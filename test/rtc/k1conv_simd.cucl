CUCL_GLOBAL_KERNEL void %(rtc_func_name)( GASQ float const * const filts, // CUCL IN in_chan:y:x:out_chan
					  GASQ float const * const biases, // CUCL IN out_chan
					  GASQ float const * const in, // CUCL IN chan:img:y:x
					  GASQ float * const out, // CUCL OUT img:chan:y:x
					  int32_t const flags )
// yeah, okay, we don't use stride/in_pad here. but in codegen, we
// check that the stride is really 1, so we must declare then here.
/* stride */  // CUCL REF y:x 
/* in_pad */  // CUCL REF y:x 
/* work */  // CUCL REF pels_blk:out_chan_blk:pels_tile:out_chan_tile:pels:out_chan
/* out_ref */  // CUCL REF img:chan:y:x
{
  // CUCL IX GRP_ID_1D work use_dims=pels_blk:out_chan_blk
  // CUCL IX LOC_ID_1D work use_dims=pels_tile:out_chan_tile
  // CUCL IX out_pel out use_dims=img:y:x
  // note: <each thread handles> work use_dims=pels:out_chan; with pels_sz==out_chan_sz==t_tile_sz (currently); loops over in.chan==filts.in_chan
  // note: for k1conv we have filts_y_dim==filts_x_dim==1

  float out_tile[%(work_pels_dim)*%(work_out_chan_dim)] = {0}; // tile of output for this thread to compute, stored in registers
  // reg. buffers for one strip each from in and filts, for the same filts_ix_out_chan_elem
  float%(vw) filts_strip[%(work_out_chan_dim)/%(vw)]; // across output chans (stride is blk_filt_ix_sz )
  float%(vw) in_strip[%(work_pels_dim)/%(vw)]; // across pels (approx square block in x/y space, favoring x if sqrt() not integer)

  int const filts_off_thr = ( %(GRP_ID_1D_out_chan_blk)*%(work_out_chan_tile_dim) + %(LOC_ID_1D_out_chan_tile) )*%(work_out_chan_dim)/%(vw)*%(filts_out_chan_sz);
  int const in_off_thr = ( %(GRP_ID_1D_pels_blk)*%(work_pels_tile_dim) + %(LOC_ID_1D_pels_tile) )*%(work_pels_dim)/%(vw)*%(in_x_sz);

  int32_t filts_off = filts_off_thr;
  int32_t in_off = in_off_thr;
  // iteratate over filter elements
  for( int32_t ic = 0; ic < %(in_chan_dim); ic += %(Kb) ) {
    %(inner_loop_body);
    filts_off += %(Kb)*%(filts_in_chan_sz)/%(vw);
    in_off += %(Kb)*%(in_chan_sz)/%(vw);
  }
  // load per-block biases into smem
  if( flags == 2 ) { return; }
  // load biases into filts_strip
  //(bias_loads);
  // add bias to each elem of out_tile[] and store the results to out[]
  int32_t out_pel = ( %(GRP_ID_1D_pels_blk)*%(work_pels_tile_dim) + %(LOC_ID_1D_pels_tile) )*%(work_pels_dim);
  int32_t out_chan = ( %(GRP_ID_1D_out_chan_blk)*%(work_out_chan_tile_dim) + %(LOC_ID_1D_out_chan_tile) )*%(work_out_chan_dim);

  float%(vw) bias_strip[%(work_out_chan_dim)/%(vw)]; // across output chans (stride is blk_filt_ix_sz ) (note: could mostly share regs with in_strip)
  for( int32_t ty = 0; ty < %(work_out_chan_dim)/%(vw); ++ty ) { bias_strip[ty] = ((GASQ float%(vw) const *)biases)[out_chan/%(vw)+ty]; }

  for( int32_t tx = 0; tx < %(work_pels_dim); ++tx, ++out_pel ) {
    if( %(out_pel_img) >= %(out_img_dim) ) { continue; } // off-the-end pixel
    int32_t out_off = ( %(out_pel_img)*%(out_img_sz) + %(out_pel_y)*%(out_y_sz) + %(out_pel_x)*%(out_x_sz) +
                        out_chan*%(out_chan_sz) );// thread-level offset into c
    %(outs_to_filts_strip);
    %(stores);
  }

  //(stores);
}

