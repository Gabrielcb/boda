Note the that caffe DSL includes various rarely-used options, features, and legacy compatibility quirks.
Rule of thumb: each new 'interesting' CNN topology needs a couple new layers/features.
Before computation can be performed, various setup and error checking must be performed on the specified net.
In particular, the sizes of the input must be propagated though the net to determine the size of the output and all intermediate nodes
Our proposed IR sits between these parsing and setup activities and the computation
Construct DAG of nodes and operations using simple C++ structures
Alexnet and nin are 'sticks' â€“ just simple pipelines
Googlenet has some small-scale split and reconvergence ('inception' layers)
Node are N-D arrays, generally representing multi-channel images: CxWxH
Operations are the atomic semantic computational units of the IR listed above, annotated with any needed parameters.
The operation type, its parameters, and the sizes of it's input and output nodes are sufficient to precisely define the input-output semantics of the operation node.


Instead, we could use Caffe to perform computations for us
Caffe, in turn, uses either the (closed) cuDNN library to 'directly' compute convolutions, or uses data transformations + the (closed) cuBLAS library.
It is certainly possible to perform various experiments using Caffe as a base, particurlar if we're only interested in accuracy, not computational speed.
Other deep learning frameworks, such as cuda-convnet2 and others, provide more open and customized CUDA implementations of convolutions. But, due to the complexity and volume of CUDA code templates, It is not clear how good a platform for experimentation they would form.

